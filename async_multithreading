https://ru.stackoverflow.com/questions/445768/%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D0%BF%D0%BE%D1%82%D0%BE%D1%87%D0%BD%D0%BE%D0%B5-vs-%D0%B0%D1%81%D0%B8%D0%BD%D1%85%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5


////////////////////////////////////


Многопоточное программирование подразумевает, 
  что код приложения выполняется в разных потоках. Например, есть главный поток UI, 
  и несколько рабочих потоков, которые выполняют тяжелые вычисления, результаты которых затем выводятся на UI.

Асинхронное программирование подразумевает 
  инициацию некоторой операцию, об окончании которой главный поток узнает спустя некоторое время. 
  Обычно это применяется для работы с системой ввода-вывода: диски, сеть и т.д.
  При этом, если это все сделано правильно, никакого потока нет. 
  Также часто под выражением "выполнить асинхронно" подразумевают, что выполнение некоторого кода будет произведено не в текущем потоке, 
  а в соседнем, при этом текущий поток не будет заблокирован. Но мой взгляд, это не совсем корректно.

Параллельное программирование подразумевает 
  разбиение одной задачи на независимые подзадачи, которые можно рассчитать параллельно, 
  а затем объединить результаты. Один из примеров -- это map-reduce. Это частный случай многопоточного программирования.


//////////////////////////////


Многопоточная работа - работа нескольких потоков.
  При этом не факт, что все потоки будут активны. 
  Возможно, что работает один поток, а другой спит. 
  Когда первый поток закончил работу, он может разбудить второй, а сам заснуть
Распараллеливание - разбиение одной задачи на независимые подзадачи 
  и выполнение этих подзадач одновременно разными потоками. 
  Пример: вычисление среднего значения двумерного массива. 
  Каждый поток может посчитать сумму своей строки, а потом все это объединить
Асинхронная работа - когда мы ставим какую-то задачу, 
  но не ждем ответа, а продолжаем делать свою работу. 
  А когда будет готов ответ - нас уведомят. Пример: попросить секретаря сварить кофе. 
  Мы не ждем этого кофе и занимаемся своими делами, а когда кофе будет готов - нам его принесут.



////////////////////////////////


Есть несколько разных понятий, связанных с областью параллельных вычислений.

Конкурентное исполнение (concurrency)
Параллельное исполнение (parallel execution)
Многопоточное исполнение (multithreading)
Асинхронное исполнение (asynchrony)
Каждый из этих терминов строго определен и имеет четкое значение.

Конкурентность (concurrency)
Конкурентность (*) (concurrency) - это наиболее общий термин, который говорит, что одновременно выполняется более одной задачи. 
Например, вы можете одновременно смотреть телевизор и комментить фоточки в фейсбуке. 
Винда, даже 95-я могла (**) одновременно играть музыку и показывать фотки.

(*) К сожалению, вменяемого русскоязычного термина я не знаю. Википедия говорит, что concurrent computing 
  - это параллельные вычисления, но как тогда будет parallel computing по русски?

(**) Да, вспоминается анекдот про Билла Гейтса и многозадачность винды, но, 
  теоретически винда могла делать несколько дел одновременно. Хотя и не любых.

Конкурентное исполнение - это самый общий термин, который не говорит о том, 
каким образом эта конкурентность будет получена: путем приостановки некоторых вычислительных 
элементов и их переключение на другую задачу, путем действительно одновременного исполнения, 
путем делегации работы другим устройствам или еще как-то. Это не важно.

Конкурентное исполнение говорит о том, что за определенный промежуток времени будет решена более, чем одна задача. Точка.

Параллельное исполнение
Параллельное исполнение (parallel computing) подразумевает наличие более 
одного вычислительного устройства (например, процессора), которые будут одновременно выполнять несколько задач.

Параллельное исполнение - это строгое подмножество конкурентного исполнения. 
Это значит, что на компьютере с одним процессором параллельное программирование - невозможно;)

Многопоточность
Многопоточность - это один из способов реализации конкурентного исполнения путем выделения абстракции "рабочего потока" (worker thread).

Потоки "абстрагируют" от пользователя низкоуровневые детали и позволяют выполнять 
более чем одну работу "параллельно". Операционная система, среда исполнения или библиотека прячет подробности того, 
будет многопоточное исполнение конкурентным (когда потоков больше чем физических процессоров), 
или параллельным (когда число потоков меньше или равно числу процессоров и несколько задач физически выполняются одновременно).

Асинхронное исполнение
Асинхронность (asynchrony) подразумевает, что операция может быть выполнена кем-то на стороне: 
удаленным веб-узлом, 
сервером 
или другим устройством за пределами текущего вычислительного устройства.

Основное свойство таких операций в том, что начало такой операции требует значительно меньшего времени, 
чем основная работа. Что позволяет выполнять множество асинхронных операций одновременно даже на устройстве с небольшим числом вычислительных устройств.

CPU-bound и IO-Bound операции
Еще один важный момент, с точки зрения разработчика - разница между CPU-bound и IO-bound операциями. 
CPU-Bound операции нагружают вычислительные мощности текущего устройства, а IO-Bound позволяют выполнить задачу вне текущей железки.

Разница важна тем, что число одновременных операций зависит от того, к какой категории они относятся. 
Вполне нормально запустить параллельно сотни IO-Bound операций, и надеяться, что хватит ресурсов обработать все результаты. 
Запускать же параллельно слишком большое число CPU-bound операций (больше, чем число вычислительных устройств) бессмысленно.

Возвращаясь к исходному вопросу: нет смысла выполнять в 1000 потоков метод Calc, если он является CPU-Intensive (нагружает центральный процессор), 
поскольку это приведет к падению общей эффективности вычислений. ОС-ке придется переключать несколько доступных ядер для обслуживания сотен потоков. 
А этот процесс не является дешевым.

Самым простым и эффективным способом решения CPU-Intensive задачи, заключается в использовании идиомы Fork-Join: 
задачу (например, входные данные) нужно разбить на определенное число подзадач, 
которые можно выполнить параллельно. Каждая подзадача должна быть независимой и не обращаться к разделяемым переменным/памяти. 
Затем, нужно собрать промежуточные результаты и объединить их.

